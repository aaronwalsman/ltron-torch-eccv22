[CONFIG]
epochs = 1000
test_frequency = 5
visualization_frequency = 5
checkpoint_frequency = 5

dataset = random_construction_6_6
train_split = train_episodes_4
test_split = test_4
split = test_4

test_episodes_per_epoch = 128

model = lstm

batch_size = 16
learning_rate = 0.0001

encoder_blocks = 6
encoder_channels = 512
encoder_heads = 8

decoder_blocks = 1
decoder_channels = 512
decoder_heads = 8

linear_warmup_cosine_decay = True
cosine_decay_start = 500
cosine_decay_stop = 350000

pretrained_fcn_path = "~/.cache/ltron/eccv_pretrain_lstms/random4_lstm.pt"
